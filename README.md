# [Jigsaw Unintended Bias in Toxicity Classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification)

## Top 1% solution (17/3165) by [AlexeyK](https://www.kaggle.com/akuritsyn), [Kirill Kravtsov](https://www.kaggle.com/altkirill), [Konstantin Gavrilchik](https://www.kaggle.com/dempton) and [Pavel Pleskov](https://www.kaggle.com/ppleskov) 

### Built a ML model using an ensemble of BERT (large and small) and LSTM-based language models with different loss functions to identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion.
